{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8541886,"sourceType":"datasetVersion","datasetId":5103134}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# intalling depandances \nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.decomposition import LatentDirichletAllocation\nimport joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-13T10:37:26.142863Z","iopub.execute_input":"2024-06-13T10:37:26.144102Z","iopub.status.idle":"2024-06-13T10:37:29.606856Z","shell.execute_reply.started":"2024-06-13T10:37:26.144056Z","shell.execute_reply":"2024-06-13T10:37:29.605653Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Downloading stopwords\nnltk.download('stopwords')\n\n# Loading the dataset\ndf = pd.read_csv('/kaggle/input/complains/complaints_processed.csv')\n\n# Displaying the first few rows of the dataframe\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T00:22:59.311294Z","iopub.execute_input":"2024-05-29T00:22:59.312652Z","iopub.status.idle":"2024-05-29T00:23:00.549677Z","shell.execute_reply.started":"2024-05-29T00:22:59.312587Z","shell.execute_reply":"2024-05-29T00:23:00.548258Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0           product  \\\n0           0       credit_card   \n1           1       credit_card   \n2           2    retail_banking   \n3           3  credit_reporting   \n4           4  credit_reporting   \n\n                                           narrative  \n0  purchase order day shipping amount receive pro...  \n1  forwarded message date tue subject please inve...  \n2  forwarded message cc sent friday pdt subject f...  \n3  payment history missing credit report speciali...  \n4  payment history missing credit report made mis...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>product</th>\n      <th>narrative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>credit_card</td>\n      <td>purchase order day shipping amount receive pro...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>forwarded message date tue subject please inve...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>retail_banking</td>\n      <td>forwarded message cc sent friday pdt subject f...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>credit_reporting</td>\n      <td>payment history missing credit report speciali...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>credit_reporting</td>\n      <td>payment history missing credit report made mis...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Defining stop words\nstop_words = set(stopwords.words('english'))\n\n# Preprocessing text data\ndef preprocess_text(text):\n    if isinstance(text, str):\n        tokens = [word for word in text.split() if word.lower() not in stop_words]\n        return ' '.join(tokens)\n    else:\n        return ''\n\n# Applying preprocessing\ndf['processed_complaint'] = df['narrative'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T00:23:00.551412Z","iopub.execute_input":"2024-05-29T00:23:00.551874Z","iopub.status.idle":"2024-05-29T00:23:03.904842Z","shell.execute_reply.started":"2024-05-29T00:23:00.551834Z","shell.execute_reply":"2024-05-29T00:23:03.903707Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Spliting the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(df['processed_complaint'], df['product'], test_size=0.2, random_state=42)\n\n# Creating a pipeline with TF-IDF vectorizer, StandardScaler, and Logistic Regression\npipeline = Pipeline([\n    ('tfidf', TfidfVectorizer()),\n    ('scaler', StandardScaler(with_mean=False)),  # Add StandardScaler\n    ('clf', LogisticRegression(max_iter=1000))  # Increased max_iter\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-29T00:23:03.907205Z","iopub.execute_input":"2024-05-29T00:23:03.908288Z","iopub.status.idle":"2024-05-29T00:23:03.954533Z","shell.execute_reply.started":"2024-05-29T00:23:03.908243Z","shell.execute_reply":"2024-05-29T00:23:03.953212Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Training the model\npipeline.fit(X_train, y_train)\n\n# Predicting on the test set\ny_pred = pipeline.predict(X_test)\n\n\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T00:23:03.956734Z","iopub.execute_input":"2024-05-29T00:23:03.957236Z","iopub.status.idle":"2024-05-29T00:27:13.990000Z","shell.execute_reply.started":"2024-05-29T00:23:03.957192Z","shell.execute_reply":"2024-05-29T00:27:13.987215Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.7785747267969833\nClassification Report:\n                     precision    recall  f1-score   support\n\n        credit_card       0.58      0.57      0.58      3212\n   credit_reporting       0.87      0.90      0.89     18130\n    debt_collection       0.66      0.63      0.65      4619\nmortgages_and_loans       0.66      0.64      0.65      3738\n     retail_banking       0.70      0.67      0.68      2786\n\n           accuracy                           0.78     32485\n          macro avg       0.69      0.68      0.69     32485\n       weighted avg       0.78      0.78      0.78     32485\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving the classification model\njoblib.dump(pipeline, 'text_classification_model.pkl')\n\n# Vectorize the text data using TF-IDF for LDA\ntfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\ntfidf = tfidf_vectorizer.fit_transform(df['processed_complaint'])\n\n# Defining and train the LDA model\nlda = LatentDirichletAllocation(n_components=10, random_state=42)\nlda.fit(tfidf)\n\n# Displaying the topics\ndef display_topics(model, feature_names, num_top_words):\n    for topic_idx, topic in enumerate(model.components_):\n        print(f\"Topic #{topic_idx}:\")\n        print(\" \".join([feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]))\n\ndisplay_topics(lda, tfidf_vectorizer.get_feature_names_out(), 10)\n\n# Saving the LDA model and the TF-IDF vectorizer\njoblib.dump(lda, 'lda_model.pkl')\njoblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T00:27:13.991714Z","iopub.execute_input":"2024-05-29T00:27:13.992045Z","iopub.status.idle":"2024-05-29T00:32:08.272486Z","shell.execute_reply.started":"2024-05-29T00:27:13.992018Z","shell.execute_reply":"2024-05-29T00:32:08.269514Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Topic #0:\ndebt credit reporting information report consumer letter law alleged collection\nTopic #1:\ndebt collection company credit paid car account loan vehicle report\nTopic #2:\nloan mortgage payment forbearance escrow home month paid company time\nTopic #3:\ncredit account report reporting information bureau inquiry inaccurate dispute removed\nTopic #4:\npayment card account credit bank late time told called month\nTopic #5:\ndebt account credit collection report company inquiry creditor original reporting\nTopic #6:\nitem report identity account credit remove theft unknown pulled fraudulent\nTopic #7:\nacct charge opened account balance act fraudulent dispute response writing\nTopic #8:\naccount card bank money fraud number credit transaction fund phone\nTopic #9:\npnc consumer link account block connect shall section agency information\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['tfidf_vectorizer.pkl']"},"metadata":{}}]}]}